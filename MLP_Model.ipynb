{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487592c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Prep_data_All_Patients.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fe0641",
   "metadata": {},
   "outputs": [],
   "source": [
    "supDir = '/Users/elikond/Downloads/surprisal_analysis/'\n",
    "clusterDir = '/Users/elikond/Downloads/clusters/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b73cc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchmetrics\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn import decomposition\n",
    "from sklearn import manifold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import scipy\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from operator import itemgetter\n",
    "\n",
    "import copy\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136fbde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_iterator(data_list, BATCH_SIZE = 64):\n",
    "    iterator = data.DataLoader(data_list,\n",
    "                            shuffle=True,\n",
    "                            batch_size = BATCH_SIZE)\n",
    "    return iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2761ebf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_iterators(merged_df, barcode_len):\n",
    "    data_list = list()\n",
    "    X_data = merged_df.iloc[:,4:-barcode_len-4]\n",
    "    X_arr = np.array(X_data)\n",
    "    vstack_scrna = np.vstack(X_arr).astype(float)\n",
    "    torch_tensor = torch.from_numpy(vstack_scrna)\n",
    "    for i, x in enumerate(torch_tensor):\n",
    "        data_list.append((x, merged_df['seurat_clusters'][i]))\n",
    "    iterator = create_iterator(data_list)\n",
    "    return iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc22295a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(merged_df, barcode_len):\n",
    "    train_inter, test_df = train_test_split(merged_df, stratify = merged_df['seurat_clusters'], test_size = 0.15)\n",
    "    train_df, valid_df = train_test_split(train_inter, stratify = train_inter['seurat_clusters'], test_size = 0.1)\n",
    "    \n",
    "    for df in [train_df, valid_df, test_df]:\n",
    "        df.reset_index(inplace = True, drop = True)\n",
    "        \n",
    "    train_iterator = make_iterators(train_df, barcode_len)\n",
    "    test_iterator = make_iterators(test_df, barcode_len)\n",
    "    valid_iterator = make_iterators(valid_df, barcode_len)\n",
    "    max_cluster = merged_df.seurat_clusters.max()\n",
    "    num_genes = len(merged_df.columns)\n",
    "    \n",
    "    return train_iterator, test_iterator, valid_iterator, max_cluster, num_genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788a5c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df, X_data, y_data, barcode_len, sigSubpopsDF = final(supDir, clusterDir, mesenDir, 'gb9')\n",
    "transform_data(merged_df, barcode_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d35eeb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_fc = nn.Linear(input_dim, 1000)\n",
    "        self.hidden_1 = nn.Linear(1000, 300)\n",
    "        self.drop = nn.Dropout(p = 0.2)\n",
    "       # self.batch_norm = nn.BatchNorm1d(300, affine=False)\n",
    "        self.hidden_2 = nn.Linear(300, 50)\n",
    "        self.output_fc = nn.Linear(50, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # x = [batch size, height, width]\n",
    "\n",
    "        batch_size = x.shape[0]\n",
    "\n",
    "        x = x.view(batch_size, -1)\n",
    "\n",
    "        # x = [batch size, height * width]\n",
    "\n",
    "        h = torch.tanh(self.input_fc(x))\n",
    "\n",
    "        h_1 = torch.tanh(self.hidden_1(h))\n",
    "\n",
    "        h_2 = self.drop(h_1)\n",
    "\n",
    "        #h_3 = self.batch_norm(h_2)\n",
    "\n",
    "        h_3 = torch.tanh(self.hidden_2(h_2))\n",
    "\n",
    "        y_pred = self.output_fc(h_3)\n",
    "\n",
    "        #y_pred = [batch size, output dim]\n",
    "\n",
    "        return y_pred, h_3\n",
    "\n",
    "INPUT_DIM = num_genes\n",
    "OUTPUT_DIM = max_cluster + 1\n",
    "\n",
    "model = MLP(INPUT_DIM, OUTPUT_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ca5250",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e323c62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1018f0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(y_pred, y):\n",
    "    top_pred = y_pred.argmax(1, keepdim=True)\n",
    "    correct = top_pred.eq(y.view_as(top_pred)).sum()\n",
    "    acc = correct.float() / y.shape[0]\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a5ddcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for (x, y) in tqdm(iterator, desc=\"Training\", leave=False):\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        y_pred, _ = model(x.float())\n",
    "        loss = criterion(y_pred, y)\n",
    "        acc = calculate_accuracy(y_pred, y)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8345c0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for (x, y) in tqdm(iterator, desc=\"Evaluating\", leave=False):\n",
    "\n",
    "            y_pred, h = model(x.float())\n",
    "\n",
    "            y_prob = F.softmax(y_pred, dim=-1)\n",
    "\n",
    "            loss = criterion(y_pred, y)\n",
    "\n",
    "            acc = calculate_accuracy(y_pred, y)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1b0996",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62372716",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(train_iterator, valid_iterator, test_iterator):\n",
    "    EPOCHS = 10\n",
    "\n",
    "    best_valid_loss = float('inf')\n",
    "\n",
    "    history = {'Train': {'Accuracy': [], 'Loss': []}, 'Test': {'Accuracy': [], 'Loss': []}, 'Validation': {'Accuracy': [], 'Loss': []}}\n",
    "\n",
    "    for epoch in trange(EPOCHS):\n",
    "\n",
    "        start_time = time.monotonic()\n",
    "\n",
    "        train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
    "        valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
    "        history['Train']['Loss'].append(train_loss)\n",
    "        history['Train']['Accuracy'].append(train_acc)\n",
    "        history['Validation']['Loss'].append(valid_loss)\n",
    "        history['Validation']['Accuracy'].append(valid_acc)\n",
    "\n",
    "        if valid_loss < best_valid_loss:\n",
    "            best_valid_loss = valid_loss\n",
    "\n",
    "        end_time = time.monotonic()\n",
    "\n",
    "        epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "        print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "        print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "        print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')\n",
    "\n",
    "        test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
    "\n",
    "    return test_acc\n",
    "\n",
    "final_acc = run(train_iterator, valid_iterator, test_iterator)\n",
    "print(final_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
