{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60283a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout\n",
    "from keras.layers import LeakyReLU\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import auc, plot_precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957c5c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelDataset(Dataset):\n",
    "    def __init__(self, x, y, cells_df):\n",
    "        self.X = torch.tensor(x.to_numpy(dtype='float32'))\n",
    "        self.Y = torch.tensor(list(y['barcode']))\n",
    "        self.Xdf = x\n",
    "        self.Ydf = y\n",
    "        self.cells = cells_df.loc[x.index,:]\n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.Y[index]\n",
    "    def __len__(self):\n",
    "        return len(self.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15e570f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data = torch.load('/Users/elikond/Desktop/wcr8_model_data__inputs_scRNA_sa_nomt__labels_barcodes.pt')\n",
    "train_data = model_data['train_data']\n",
    "test_data = model_data['test_data']\n",
    "valid_data = model_data['val_data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b974ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(train_data.Xdf)\n",
    "X_test = np.array(test_data.Xdf)\n",
    "X_valid = np.array(valid_data.Xdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e28b087",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = train_data.Ydf\n",
    "Y_test = test_data.Ydf\n",
    "Y_valid = valid_data.Ydf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a186ab97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_y(Y):\n",
    "    process_columns = [\"Process {}\".format(i+1) for i in range(6)]\n",
    "    Y[process_columns] = pd.DataFrame(Y['barcode'].tolist(), index= Y.index)\n",
    "    Y_new = Y.iloc[:,2:].astype(int)\n",
    "    return np.array(Y_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648490d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = convert_y(Y_train)\n",
    "y_test = convert_y(Y_test)\n",
    "y_valid = convert_y(Y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb621a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(optimizer=\"RMSprop\",init='uniform'):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(16, input_dim=1806, activation=LeakyReLU()))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(27, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(7, activation='sigmoid'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(27, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(6, activation='softmax'))\n",
    "    \n",
    "    def sk_pr_auc(y_true, y_pred):\n",
    "        auprcs = list()\n",
    "        for i in range(6):\n",
    "            precision, recall, thresholds = precision_recall_curve(tf.gather(y_true, i, axis=1), tf.gather(y_pred, i, axis=1))\n",
    "            auc_precision_recall = auc(recall, precision)\n",
    "            auprcs.append(auc_precision_recall)\n",
    "        return sum(auprcs) / len(auprcs)\n",
    "    \n",
    "    def processes(y_true, y_pred):\n",
    "        auprs = list()\n",
    "        for i in range(6):\n",
    "        precision, recall, thresholds = precision_recall_curve(tf.gather(y_true, i, axis=1), tf.gather(y_pred, i, axis=1))\n",
    "        auc_precision_recall = auc(recall, precision)\n",
    "        return auprs\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer,\n",
    "                  metrics=[\"accuracy\", sk_pr_auc, processes], run_eagerly=True)\n",
    "    return model\n",
    "\n",
    "model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefb460c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train=model.fit(X_train, y_train, epochs=50, batch_size=50, verbose=0,validation_data=(X_valid,y_valid))\n",
    "\n",
    "plt.plot(train.history['sk_pr_auc'], label='train')\n",
    "plt.plot(train.history['val_sk_pr_auc'], label='test')\n",
    "plt.title('WCR8 Macro-Averaged AUPRC')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Macro AUPRC')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "\n",
    "grid_theme = {'axes.grid': True}\n",
    "matplotlib.rcParams.update(grid_theme)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42862a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(train.history['sk_pr_auc'], label='Train')\n",
    "plt.plot(train.history['val_sk_pr_auc'], label='Validation')\n",
    "plt.title('WCR8 Macro-Averaged AUPRC')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Macro AUPRC')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "\n",
    "grid_theme = {'axes.grid': True}\n",
    "plt.rcParams.update(grid_theme)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0125cf7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b96e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554a21b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train.history['sk_pr_auc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268bc521",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "   \n",
    "    'epochs': [50,75,100], \n",
    "    'batch_size':[32,50,100],\n",
    "    'optimizer':['RMSprop', 'Adam','SGD'],\n",
    "    \n",
    "}\n",
    "\n",
    "# create model\n",
    "\n",
    "# Creating Model Object with KerasClassifier\n",
    "model_cv = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "\n",
    "grid = GridSearchCV(estimator=model_cv,  \n",
    "                    n_jobs=-1, \n",
    "                    verbose=1,\n",
    "                    cv=5,\n",
    "                    param_grid=param_grid)\n",
    "\n",
    "grid_cv_model = grid.fit(X_train, y_train,) # Fitting the GridSearch Object on the Train Set\n",
    "\n",
    "# Printing the Best Parameters as a Result of Grid Search Cross Validation on the Screen\n",
    "print(\"Best: %f using %s\" % (grid_cv_model.best_score_, grid_cv_model.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82c7750",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_model = grid_cv_model.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99f0f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X_test)\n",
    "\n",
    "precision = dict()\n",
    "recall = dict()\n",
    "plt.figure(figsize=(20,20))\n",
    "for i in range(6):\n",
    "    precision[i], recall[i], _ = precision_recall_curve(y_test[:, i],\n",
    "                                                        pred[:, i])    \n",
    "    plt.subplot(1,6,i+1)\n",
    "    plt.plot(recall[i], precision[i], lw=2)\n",
    "    plt.title('Process' + str(i))\n",
    "    \n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"WCR8 Test Precision-Recall Curves\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30797cc1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "j = 0\n",
    "for i in range(6):\n",
    "    precision, recall, thresholds = precision_recall_curve(tf.gather(y_test, i, axis=1), tf.gather(pred, i, axis=1))\n",
    "    auc_precision_recall = auc(recall, precision)\n",
    "    j += auc_precision_recall\n",
    "    print(auc_precision_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a149d3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_probs = model.predict(X_test)[:,0]\n",
    "y_test_preds = (model.predict(X_test) > 0.5).astype(\"int32\")[:,0]\n",
    "\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "\n",
    "# Define probability thresholds to use, between 0 and 1\n",
    "probability_thresholds = np.linspace(0, 1, num=100)\n",
    "\n",
    "# Find true positive / false positive rate for each threshold\n",
    "for p in probability_thresholds:\n",
    "    \n",
    "    y_test_preds = []\n",
    "    \n",
    "    for prob in y_test_probs:\n",
    "        if prob > p:\n",
    "            y_test_preds.append(1)\n",
    "        else:\n",
    "            y_test_preds.append(0)\n",
    "            \n",
    "    precision, recall, _ = precision_recall_curve(y_test[:,0], y_test_preds)\n",
    "    print(recall)    \n",
    "    \n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "\n",
    "plt.plot(recall_scores, precision_scores, lw=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
